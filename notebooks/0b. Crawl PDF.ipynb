{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdcb8f3c",
   "metadata": {},
   "source": [
    "# Crawl all PDF files for text and statistics\n",
    "Here we scrape all the PDFs and extract text data and statistics from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b15b9499",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba524d57",
   "metadata": {},
   "source": [
    "## Read submission list\n",
    "Here we scrape the _notes_ , (list of all submissions) using OpenReview's API, way faster than Selenium-based scraping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d02c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "venue = 'ICLR.cc/2023/Conference'\n",
    "venue_short = 'iclr2023'\n",
    "date = time.strftime(\"%Y%m%d\")\n",
    "\n",
    "# Read hdf5 file\n",
    "df = pd.read_hdf(DATA_PATH + f'{venue_short}_data_full_{date}.h5', key='df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5841d6a3",
   "metadata": {},
   "source": [
    "## Download PDFs and crawl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554052ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pdfs from df['content.pdf']\n",
    "def download_pdf(url, filename):\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(filename, 'wb').write(r.content)\n",
    "\n",
    "def download_pdf(url, filename):\n",
    "    try:\n",
    "        r = requests.get(url, allow_redirects=True, timeout=10)\n",
    "        r.raise_for_status()\n",
    "        open(filename, 'wb').write(r.content)\n",
    "        return\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Error downloading {filename}: Request timed out\")\n",
    "    except e:\n",
    "        print(f\"Error downloading {filename}: {e}\")\n",
    "\n",
    "\n",
    "def retry_get_pdf_data(url, filename, extra='', timeout=5, retries=10):\n",
    "    num_retries = 0\n",
    "    for i in range(retries):\n",
    "        if download_pdf(url, filename, timeout=timeout):\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Error downloading {filename}: {extra}\")\n",
    "            time.sleep(1)\n",
    "            num_retries += 1\n",
    "            if num_retries >= retries:\n",
    "                print(f\"Error downloading {filename}: {extra}\")\n",
    "                break\n",
    "    \n",
    "\n",
    "def get_pdf_data(id, save_dir='temp/'):\n",
    "    try:\n",
    "        # Make temp directory if not exis\n",
    "        save_dir = Path(save_dir)\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        BASE_URL = 'https://openreview.net/pdf?id='\n",
    "        filename = save_dir / (id + '.pdf')\n",
    "        download_pdf(BASE_URL + id, filename)\n",
    "\n",
    "        # Read pdf\n",
    "        reader = PdfReader(filename)\n",
    "        number_of_pages = len(reader.pages)\n",
    "        file_size = os.stat(filename).st_size\n",
    "        text_all = ''\n",
    "        num_characters = 0\n",
    "        for page in reader.pages:\n",
    "            text = page.extract_text()\n",
    "            # text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
    "            text_all += text\n",
    "            num_characters += len(text)\n",
    "\n",
    "        # Delete pdf\n",
    "        os.remove(filename)\n",
    "        return {'id': id, 'text': text_all, 'num_characters': num_characters, 'num_pages': number_of_pages, 'file_size': file_size}\n",
    "    except:\n",
    "        return {'id': id, 'text': '', 'num_characters': 0, 'num_pages': 0, 'file_size': 0}\n",
    "\n",
    "\n",
    "# Use multiprocessing to download pdfs\n",
    "def get_pdf_multi(ids, ratio=0.8):\n",
    "    num_processes = int(ratio*mp.cpu_count())\n",
    "    with Pool(num_processes) as p:\n",
    "        data = list(tqdm(p.imap(get_pdf_data, ids), total=len(ids)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f47ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd7e05259294efbb759f7edc260420c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4874 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown widths : \n",
      "[0, IndirectObject(317, 0, 140366911357040)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(319, 0, 140366911357040)]\n",
      "FloatObject (b'0.00-86730235') invalid; use 0.0 instead\n",
      "FloatObject (b'0.000000000000-15543122') invalid; use 0.0 instead\n",
      "FloatObject (b'0.000000000000-19539925') invalid; use 0.0 instead\n",
      "FloatObject (b'0.0000000000000-35527137') invalid; use 0.0 instead\n",
      "FloatObject (b'0.0000000000000-71054274') invalid; use 0.0 instead\n",
      "FloatObject (b'0.000000000000-14210855') invalid; use 0.0 instead\n",
      "FloatObject (b'0.000000000000-38339703') invalid; use 0.0 instead\n",
      "FloatObject (b'0.0000000000000000000000000000-4256562') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00000000000-11368684') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-50') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-50') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-50') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-50') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-27322833') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-21119324') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00000000000-22737368') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00000000000-22737368') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-20839895') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-10') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-9881419') invalid; use 0.0 instead\n",
      "unknown widths : \n",
      "[0, IndirectObject(358, 0, 140366910114208)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(360, 0, 140366910114208)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(406, 0, 140366910114208)]\n",
      "FloatObject (b'0.000000000000-5684342') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-70') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-70') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-70') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-70') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-50') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-50') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-50') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-50') invalid; use 0.0 instead\n",
      "unknown widths : \n",
      "[0, IndirectObject(1118, 0, 140366881742064)]\n",
      "unknown widths : \n",
      "[0, IndirectObject(1120, 0, 140366881742064)]\n",
      "/home/botu/.local/lib/python3.10/site-packages/PyPDF2/_cmap.py:142: PdfReadWarning: Advanced encoding /GBK-EUC-H not implemented yet\n",
      "  warnings.warn(\n",
      "FloatObject (b'0.00-5113345') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-30') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-30') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-30') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-30') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-30') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-30') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-30') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-30') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-68031496') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-68031496') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-68031496') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-68031496') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-68031496') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-68031496') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-68031496') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-68031496') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-68031496') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-68031496') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-40') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-40') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-40') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-40') invalid; use 0.0 instead\n",
      "Multiple definitions in dictionary at byte 0x66ef for key /x15\n",
      "Multiple definitions in dictionary at byte 0x66fb for key /x15\n",
      "Multiple definitions in dictionary at byte 0x6707 for key /x15\n",
      "Multiple definitions in dictionary at byte 0x66ffc for key /x42\n",
      "Multiple definitions in dictionary at byte 0x67008 for key /x42\n",
      "Multiple definitions in dictionary at byte 0x67038 for key /x42\n",
      "Multiple definitions in dictionary at byte 0x67044 for key /x42\n",
      "Multiple definitions in dictionary at byte 0x67068 for key /x42\n",
      "Multiple definitions in dictionary at byte 0x38b4 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x3d3e for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x39ff for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x3aa5 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x3384 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x3c98 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x3429 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x3b4c for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x3195 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x380e for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x323a for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x3e8a for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x361c for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x3575 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x34d0 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x3de5 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x3959 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x30ee for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x3049 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x3768 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x32df for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x36c3 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x3bf1 for key /ToUnicode\n",
      "FloatObject (b'0.000000000000-14210855') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-40') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-40') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-40') invalid; use 0.0 instead\n",
      "FloatObject (b'0.00-40') invalid; use 0.0 instead\n",
      "FloatObject (b'0.000000000000-2842171') invalid; use 0.0 instead\n"
     ]
    }
   ],
   "source": [
    "# Get pdf data\n",
    "data = get_pdf_multi(df['id'].values.tolist(), ratio=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea60ea22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>file_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4871</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873</th>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id text  num_characters  num_pages  file_size\n",
       "4869  NaN                    0          0          0\n",
       "4870  NaN                    0          0          0\n",
       "4871  NaN                    0          0          0\n",
       "4872  NaN                    0          0          0\n",
       "4873  NaN                    0          0          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497067d",
   "metadata": {},
   "source": [
    "## Save dataset as `hdf5` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c666c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_895716/3099490284.py:1: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index(['id', 'text'], dtype='object')]\n",
      "\n",
      "  data.to_hdf(DATA_PATH + f'{venue_short}_pdf_data_{time.strftime(\"%Y%m%d\")}.h5', key='df', mode='a')\n"
     ]
    }
   ],
   "source": [
    "data.to_hdf(DATA_PATH + f'{venue_short}_pdf_data_{time.strftime(\"%Y%m%d\")}.h5', key='df', mode='a')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1fefe16",
   "metadata": {},
   "source": [
    "## (optional) get older data parsed before results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24d87006",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_hdf(DATA_PATH + f'{venue_short}_pdf_data_{time.strftime(\"%Y%m%d\")}.h5', key='df')\n",
    "old_df = pd.read_hdf(f'{venue_short}_pdf_data_20221120.h5', key='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b3259ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>file_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUzSobdYy0V</td>\n",
       "      <td>QUANTIFYING AND MITIGATING THE IMPACT OF LA-\\n...</td>\n",
       "      <td>78841</td>\n",
       "      <td>27</td>\n",
       "      <td>1959287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N3kGYG3ZcTi</td>\n",
       "      <td>Under review as a conference paper at ICLR 202...</td>\n",
       "      <td>24857</td>\n",
       "      <td>8</td>\n",
       "      <td>199010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tmIiMPl4IPa</td>\n",
       "      <td>Under review as a conference paper at ICLR 202...</td>\n",
       "      <td>53125</td>\n",
       "      <td>17</td>\n",
       "      <td>5864879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mhnHqRqcjYU</td>\n",
       "      <td>Under review as a conference paper at ICLR 202...</td>\n",
       "      <td>77689</td>\n",
       "      <td>25</td>\n",
       "      <td>2192779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sZI1Oj9KBKy</td>\n",
       "      <td>Under review as a conference paper at ICLR 202...</td>\n",
       "      <td>81745</td>\n",
       "      <td>27</td>\n",
       "      <td>4586711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text  \\\n",
       "0  RUzSobdYy0V  QUANTIFYING AND MITIGATING THE IMPACT OF LA-\\n...   \n",
       "1  N3kGYG3ZcTi  Under review as a conference paper at ICLR 202...   \n",
       "2  tmIiMPl4IPa  Under review as a conference paper at ICLR 202...   \n",
       "3  mhnHqRqcjYU  Under review as a conference paper at ICLR 202...   \n",
       "4  sZI1Oj9KBKy  Under review as a conference paper at ICLR 202...   \n",
       "\n",
       "   num_characters  num_pages  file_size  \n",
       "0           78841         27    1959287  \n",
       "1           24857          8     199010  \n",
       "2           53125         17    5864879  \n",
       "3           77689         25    2192779  \n",
       "4           81745         27    4586711  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8d94fd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing 1023 papers\n"
     ]
    }
   ],
   "source": [
    "# Merge entries from df_old with id = NaN\n",
    "# Overwrite data from old_df with new_df if id is not NaN\n",
    "\n",
    "ids = old_df['id'].values.tolist()\n",
    "\n",
    "\n",
    "papers = []\n",
    "missing = 0\n",
    "for i, id in enumerate(ids):\n",
    "    # search for id in new_df\n",
    "    paper_old = old_df[old_df['id'] == id]\n",
    "    paper_new = new_df[new_df['id'] == id]\n",
    "    \n",
    "    # if no paper new, then keep old\n",
    "    if len(paper_new) == 0:\n",
    "        papers.append(paper_old)\n",
    "        missing += 1\n",
    "    else:\n",
    "        papers.append(paper_new)\n",
    "\n",
    "df = pd.concat(papers)\n",
    "df = df.reset_index(drop=True)\n",
    "print(f\"Missing {missing} papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1f2d313e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>file_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>IJwhRE510b</td>\n",
       "      <td>Under review as a conference paper at ICLR 202...</td>\n",
       "      <td>65682</td>\n",
       "      <td>18</td>\n",
       "      <td>1817942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>4XMAzZasId</td>\n",
       "      <td>Under review as a conference paper at ICLR 202...</td>\n",
       "      <td>102838</td>\n",
       "      <td>29</td>\n",
       "      <td>822566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4871</th>\n",
       "      <td>KjKZaJ5Gbv</td>\n",
       "      <td>Under review as a conference paper at ICLR 202...</td>\n",
       "      <td>56608</td>\n",
       "      <td>14</td>\n",
       "      <td>5518446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>ED2Jjms9A4H</td>\n",
       "      <td>Under review as a conference paper at ICLR 202...</td>\n",
       "      <td>70902</td>\n",
       "      <td>20</td>\n",
       "      <td>11203876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873</th>\n",
       "      <td>jU-AXLS2bl</td>\n",
       "      <td>Under review as a conference paper at ICLR 202...</td>\n",
       "      <td>47722</td>\n",
       "      <td>15</td>\n",
       "      <td>1766995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                               text  \\\n",
       "4869   IJwhRE510b  Under review as a conference paper at ICLR 202...   \n",
       "4870   4XMAzZasId  Under review as a conference paper at ICLR 202...   \n",
       "4871   KjKZaJ5Gbv  Under review as a conference paper at ICLR 202...   \n",
       "4872  ED2Jjms9A4H  Under review as a conference paper at ICLR 202...   \n",
       "4873   jU-AXLS2bl  Under review as a conference paper at ICLR 202...   \n",
       "\n",
       "      num_characters  num_pages  file_size  \n",
       "4869           65682         18    1817942  \n",
       "4870          102838         29     822566  \n",
       "4871           56608         14    5518446  \n",
       "4872           70902         20   11203876  \n",
       "4873           47722         15    1766995  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "62ecbd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf(DATA_PATH + f'{venue_short}_pdf_data_{time.strftime(\"%Y%m%d\")}.h5', key='df', mode='a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
