{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdcb8f3c",
   "metadata": {},
   "source": [
    "# OpenReview Venue Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b15b9499",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba524d57",
   "metadata": {},
   "source": [
    "## Scrape list of all submissions\n",
    "Here we scrape the _notes_ , (list of all submissions) using OpenReview's API, way faster than Selenium-based scraping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d02c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "venue = 'ICLR.cc/2023/Conference'\n",
    "venue_short = 'iclr2023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a451ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conference_notes(venue, blind_submission=False):\n",
    "    \"\"\"\n",
    "    Get all notes of a conference (data) from OpenReview API.\n",
    "    If results are not final, you should set blind_submission=True.\n",
    "    \"\"\"\n",
    "\n",
    "    blind_param = '-/Blind_Submission' if blind_submission else ''\n",
    "    offset = 0\n",
    "    notes = []\n",
    "    while True:\n",
    "        print('Offset:', offset, 'Data:', len(notes))\n",
    "        url = f'https://api.openreview.net/notes?invitation={venue}/{blind_param}&offset={offset}'\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        if len(data['notes']) == 0:\n",
    "            break\n",
    "        offset += 1000\n",
    "        notes.extend(data['notes'])\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c6974ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset: 0 Data: 0\n",
      "Offset: 1000 Data: 1000\n",
      "Offset: 2000 Data: 2000\n",
      "Offset: 3000 Data: 3000\n",
      "Offset: 4000 Data: 4000\n",
      "Offset: 5000 Data: 4875\n",
      "Number of submissions: 4875\n"
     ]
    }
   ],
   "source": [
    "raw_notes = get_conference_notes(venue, blind_submission=True)\n",
    "print(\"Number of submissions:\", len(raw_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d074dc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original</th>\n",
       "      <th>number</th>\n",
       "      <th>cdate</th>\n",
       "      <th>mdate</th>\n",
       "      <th>ddate</th>\n",
       "      <th>tcdate</th>\n",
       "      <th>tmdate</th>\n",
       "      <th>tddate</th>\n",
       "      <th>forum</th>\n",
       "      <th>...</th>\n",
       "      <th>content.no_acknowledgement_section</th>\n",
       "      <th>content.code_of_ethics</th>\n",
       "      <th>content.submission_guidelines</th>\n",
       "      <th>content.resubmission</th>\n",
       "      <th>content.student_author</th>\n",
       "      <th>content.Please_choose_the_closest_area_that_your_submission_falls_into</th>\n",
       "      <th>content.paperhash</th>\n",
       "      <th>content.pdf</th>\n",
       "      <th>content._bibtex</th>\n",
       "      <th>content.supplementary_material</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kRvZ2PcsxjJj</td>\n",
       "      <td>cnlsip-X_k</td>\n",
       "      <td>6623</td>\n",
       "      <td>1663850591061</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1663850591061</td>\n",
       "      <td>1666794126677</td>\n",
       "      <td>None</td>\n",
       "      <td>kRvZ2PcsxjJj</td>\n",
       "      <td>...</td>\n",
       "      <td>I certify that there is no acknowledgement sec...</td>\n",
       "      <td>I acknowledge that I and all co-authors of thi...</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Reinforcement Learning (eg, decision and contr...</td>\n",
       "      <td>anonymous|quantum_reinforcement_learning</td>\n",
       "      <td>/pdf/bd1412beeb070314478ba69a52979cd9d7057106.pdf</td>\n",
       "      <td>@inproceedings{\\nanonymous2023quantum,\\ntitle=...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RUzSobdYy0V</td>\n",
       "      <td>pmo4AKuE4-p</td>\n",
       "      <td>6620</td>\n",
       "      <td>1663850590815</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1663850590815</td>\n",
       "      <td>1666794126368</td>\n",
       "      <td>None</td>\n",
       "      <td>RUzSobdYy0V</td>\n",
       "      <td>...</td>\n",
       "      <td>I certify that there is no acknowledgement sec...</td>\n",
       "      <td>I acknowledge that I and all co-authors of thi...</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Social Aspects of Machine Learning (eg, AI saf...</td>\n",
       "      <td>anonymous|quantifying_and_mitigating_the_impac...</td>\n",
       "      <td>/pdf/fa20300b4f58971f6a0663a5cb2c8efd17fe6240.pdf</td>\n",
       "      <td>@inproceedings{\\nanonymous2023quantifying,\\nti...</td>\n",
       "      <td>/attachment/151652f4d981a49f9dfa81be992839a243...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N3kGYG3ZcTi</td>\n",
       "      <td>kVYulJycT2K</td>\n",
       "      <td>6611</td>\n",
       "      <td>1663850589829</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1663850589829</td>\n",
       "      <td>1666794126045</td>\n",
       "      <td>None</td>\n",
       "      <td>N3kGYG3ZcTi</td>\n",
       "      <td>...</td>\n",
       "      <td>I certify that there is no acknowledgement sec...</td>\n",
       "      <td>I acknowledge that I and all co-authors of thi...</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Deep Learning and representational learning</td>\n",
       "      <td>anonymous|suppression_helps_lateral_inhibition...</td>\n",
       "      <td>/pdf/fe61792a0bdac18c97e72754f6fd250b79e65ffc.pdf</td>\n",
       "      <td>@inproceedings{\\nanonymous2023suppression,\\nti...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tmIiMPl4IPa</td>\n",
       "      <td>RAIF4RUF0T</td>\n",
       "      <td>6610</td>\n",
       "      <td>1663850589709</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1663850589709</td>\n",
       "      <td>1666794125709</td>\n",
       "      <td>None</td>\n",
       "      <td>tmIiMPl4IPa</td>\n",
       "      <td>...</td>\n",
       "      <td>I certify that there is no acknowledgement sec...</td>\n",
       "      <td>I acknowledge that I and all co-authors of thi...</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Machine Learning for Sciences (eg biology, phy...</td>\n",
       "      <td>anonymous|factorized_fourier_neural_operators</td>\n",
       "      <td>/pdf/f165fba1a61fac089a88a6f600dafa6100768f5c.pdf</td>\n",
       "      <td>@inproceedings{\\nanonymous2023factorized,\\ntit...</td>\n",
       "      <td>/attachment/528ca783f12ed545d4727d9b5edcb4e4d3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mhnHqRqcjYU</td>\n",
       "      <td>ix_LR-W0OM2</td>\n",
       "      <td>6603</td>\n",
       "      <td>1663850588877</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1663850588877</td>\n",
       "      <td>1666794125400</td>\n",
       "      <td>None</td>\n",
       "      <td>mhnHqRqcjYU</td>\n",
       "      <td>...</td>\n",
       "      <td>I certify that there is no acknowledgement sec...</td>\n",
       "      <td>I acknowledge that I and all co-authors of thi...</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Deep Learning and representational learning</td>\n",
       "      <td>anonymous|dfpc_data_flow_driven_pruning_of_cou...</td>\n",
       "      <td>/pdf/55db83e926f940361b1f96359cd90eb9e5461681.pdf</td>\n",
       "      <td>@inproceedings{\\nanonymous2023dfpc,\\ntitle={{D...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     original  number          cdate mdate ddate  \\\n",
       "0  kRvZ2PcsxjJj   cnlsip-X_k    6623  1663850591061  None  None   \n",
       "1   RUzSobdYy0V  pmo4AKuE4-p    6620  1663850590815  None  None   \n",
       "2   N3kGYG3ZcTi  kVYulJycT2K    6611  1663850589829  None  None   \n",
       "3   tmIiMPl4IPa   RAIF4RUF0T    6610  1663850589709  None  None   \n",
       "4   mhnHqRqcjYU  ix_LR-W0OM2    6603  1663850588877  None  None   \n",
       "\n",
       "          tcdate         tmdate tddate         forum  ...  \\\n",
       "0  1663850591061  1666794126677   None  kRvZ2PcsxjJj  ...   \n",
       "1  1663850590815  1666794126368   None   RUzSobdYy0V  ...   \n",
       "2  1663850589829  1666794126045   None   N3kGYG3ZcTi  ...   \n",
       "3  1663850589709  1666794125709   None   tmIiMPl4IPa  ...   \n",
       "4  1663850588877  1666794125400   None   mhnHqRqcjYU  ...   \n",
       "\n",
       "                  content.no_acknowledgement_section  \\\n",
       "0  I certify that there is no acknowledgement sec...   \n",
       "1  I certify that there is no acknowledgement sec...   \n",
       "2  I certify that there is no acknowledgement sec...   \n",
       "3  I certify that there is no acknowledgement sec...   \n",
       "4  I certify that there is no acknowledgement sec...   \n",
       "\n",
       "                              content.code_of_ethics  \\\n",
       "0  I acknowledge that I and all co-authors of thi...   \n",
       "1  I acknowledge that I and all co-authors of thi...   \n",
       "2  I acknowledge that I and all co-authors of thi...   \n",
       "3  I acknowledge that I and all co-authors of thi...   \n",
       "4  I acknowledge that I and all co-authors of thi...   \n",
       "\n",
       "  content.submission_guidelines content.resubmission content.student_author  \\\n",
       "0                           Yes                                               \n",
       "1                           Yes                                               \n",
       "2                           Yes                                               \n",
       "3                           Yes                                               \n",
       "4                           Yes                                               \n",
       "\n",
       "  content.Please_choose_the_closest_area_that_your_submission_falls_into  \\\n",
       "0  Reinforcement Learning (eg, decision and contr...                       \n",
       "1  Social Aspects of Machine Learning (eg, AI saf...                       \n",
       "2        Deep Learning and representational learning                       \n",
       "3  Machine Learning for Sciences (eg biology, phy...                       \n",
       "4        Deep Learning and representational learning                       \n",
       "\n",
       "                                   content.paperhash  \\\n",
       "0           anonymous|quantum_reinforcement_learning   \n",
       "1  anonymous|quantifying_and_mitigating_the_impac...   \n",
       "2  anonymous|suppression_helps_lateral_inhibition...   \n",
       "3      anonymous|factorized_fourier_neural_operators   \n",
       "4  anonymous|dfpc_data_flow_driven_pruning_of_cou...   \n",
       "\n",
       "                                         content.pdf  \\\n",
       "0  /pdf/bd1412beeb070314478ba69a52979cd9d7057106.pdf   \n",
       "1  /pdf/fa20300b4f58971f6a0663a5cb2c8efd17fe6240.pdf   \n",
       "2  /pdf/fe61792a0bdac18c97e72754f6fd250b79e65ffc.pdf   \n",
       "3  /pdf/f165fba1a61fac089a88a6f600dafa6100768f5c.pdf   \n",
       "4  /pdf/55db83e926f940361b1f96359cd90eb9e5461681.pdf   \n",
       "\n",
       "                                     content._bibtex  \\\n",
       "0  @inproceedings{\\nanonymous2023quantum,\\ntitle=...   \n",
       "1  @inproceedings{\\nanonymous2023quantifying,\\nti...   \n",
       "2  @inproceedings{\\nanonymous2023suppression,\\nti...   \n",
       "3  @inproceedings{\\nanonymous2023factorized,\\ntit...   \n",
       "4  @inproceedings{\\nanonymous2023dfpc,\\ntitle={{D...   \n",
       "\n",
       "                      content.supplementary_material  \n",
       "0                                                NaN  \n",
       "1  /attachment/151652f4d981a49f9dfa81be992839a243...  \n",
       "2                                                NaN  \n",
       "3  /attachment/528ca783f12ed545d4727d9b5edcb4e4d3...  \n",
       "4                                                NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.json_normalize(raw_notes)\n",
    "# set index as first column\n",
    "# df_raw.set_index(df_raw.columns[0], inplace=True)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1c02af",
   "metadata": {},
   "source": [
    "## Scrape forums of each submission\n",
    "Here we scrape the forums of each submissions, it can be pretty fast thanks to:\n",
    "- OpenReview's API (we use requests)\n",
    "- Multiprocessing to parallelize the scraping of each paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "139f9b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiprocessing pool of requests over index of dataframe\n",
    "\n",
    "extra = \"trash=true&details=replyCount%2Cwritable%2Crevisions%2Coriginal%2Coverwriting%2Cinvitation%2Ctags\"\n",
    "\n",
    "def get_paper_data(paper_id):\n",
    "    try:\n",
    "        url = f\"https://api.openreview.net/notes?forum={paper_id}&{extra}\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        return data\n",
    "    except:\n",
    "        print(f\"Error for paper {paper_id}\")\n",
    "        return None\n",
    "\n",
    "def get_paper_data_multi(paper_ids, ratio=0.8):\n",
    "    num_processes = int(ratio*mp.cpu_count())\n",
    "    with Pool(num_processes) as p:\n",
    "        data = list(tqdm(p.imap(get_paper_data, paper_ids), total=len(paper_ids)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "969f4cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content.title</th>\n",
       "      <th>content.keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kRvZ2PcsxjJj</td>\n",
       "      <td>Quantum reinforcement learning</td>\n",
       "      <td>[quantum reinforcement learning, multi-agent, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RUzSobdYy0V</td>\n",
       "      <td>Quantifying and Mitigating the Impact of Label...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N3kGYG3ZcTi</td>\n",
       "      <td>Suppression helps: Lateral Inhibition-inspired...</td>\n",
       "      <td>[Lateral Inhibition, Convolutional Neural Netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tmIiMPl4IPa</td>\n",
       "      <td>Factorized Fourier Neural Operators</td>\n",
       "      <td>[fourier transform, fourier operators, pde, na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mhnHqRqcjYU</td>\n",
       "      <td>DFPC: Data flow driven pruning of coupled chan...</td>\n",
       "      <td>[Pruning, Data Free, Model Compression]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                      content.title  \\\n",
       "0  kRvZ2PcsxjJj                    Quantum reinforcement learning    \n",
       "1   RUzSobdYy0V  Quantifying and Mitigating the Impact of Label...   \n",
       "2   N3kGYG3ZcTi  Suppression helps: Lateral Inhibition-inspired...   \n",
       "3   tmIiMPl4IPa                Factorized Fourier Neural Operators   \n",
       "4   mhnHqRqcjYU  DFPC: Data flow driven pruning of coupled chan...   \n",
       "\n",
       "                                    content.keywords  \n",
       "0  [quantum reinforcement learning, multi-agent, ...  \n",
       "1                                                 []  \n",
       "2  [Lateral Inhibition, Convolutional Neural Netw...  \n",
       "3  [fourier transform, fourier operators, pde, na...  \n",
       "4            [Pruning, Data Free, Model Compression]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter df with only id, title, url and keywords\n",
    "df_raw_filtered = df_raw[['id', 'content.title', 'content.keywords']]\n",
    "df_raw_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e32b36c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb358b4e8c0c421cafd74a3ada254c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for paper 36g8Ept_CCjError for paper CQsmMYmlP5TError for paper LQIjzPdDt3qError for paper JmkjrlVE-DGError for paper sqPEs1wEizUError for paper 3yEIFSMwKBCError for paper YlGsTZODyjzError for paper MHgYMtHpKsCError for paper XYUaprBSDjpError for paper GVWySHBD3ClError for paper qYO0f9WnUupError for paper B4maZQLLW0_Error for paper SZYXyhE2c6f\n",
      "\n",
      "\n",
      "Error for paper 0eTTKOOOQkV\n",
      "Error for paper GVMwL15UrZO\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Error for paper Hcq7zGgcsOg\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_items\u001b[39m.\u001b[39;49mpopleft()\n\u001b[1;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/botu/Dev/ICLR2023-OpenReviewData/notebooks/0a. Parse data.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/botu/Dev/ICLR2023-OpenReviewData/notebooks/0a.%20Parse%20data.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ids \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df_raw_filtered[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/botu/Dev/ICLR2023-OpenReviewData/notebooks/0a.%20Parse%20data.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data \u001b[39m=\u001b[39m get_paper_data_multi(ids, ratio\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/home/botu/Dev/ICLR2023-OpenReviewData/notebooks/0a. Parse data.ipynb Cell 11\u001b[0m in \u001b[0;36mget_paper_data_multi\u001b[0;34m(paper_ids, ratio)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/botu/Dev/ICLR2023-OpenReviewData/notebooks/0a.%20Parse%20data.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m num_processes \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(ratio\u001b[39m*\u001b[39mmp\u001b[39m.\u001b[39mcpu_count())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/botu/Dev/ICLR2023-OpenReviewData/notebooks/0a.%20Parse%20data.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mwith\u001b[39;00m Pool(num_processes) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/botu/Dev/ICLR2023-OpenReviewData/notebooks/0a.%20Parse%20data.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(tqdm(p\u001b[39m.\u001b[39;49mimap(get_paper_data, paper_ids), total\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(paper_ids)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/botu/Dev/ICLR2023-OpenReviewData/notebooks/0a.%20Parse%20data.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/notebook.py:258\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> 258\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    259\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    260\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m    261\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 861\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    862\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    863\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items\u001b[39m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ids = list(df_raw_filtered['id'])\n",
    "data = get_paper_data_multi(ids, ratio=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667bdae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only notes\n",
    "notes = [d['notes'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55385088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(item, \n",
    "                review_keys=['summary_of_the_paper', 'main_review', 'summary_of_the_review']\n",
    "                ):\n",
    "    \"\"\"Filter only ratings, confidence, withdraw status and decisions\"\"\"\n",
    "    # parse each note\n",
    "    withdraw = 0\n",
    "    # filter meta note\n",
    "    meta_note = [d for d in item if 'Paper' not in d['invitation']]\n",
    "    # check withdrawn\n",
    "    withdraw = 1 if 'Withdrawn_Submission' in meta_note[0]['invitation'] else 0\n",
    "    # decision\n",
    "    if withdraw == 0:\n",
    "        decision_note = [d for d in item if 'Decision' in d['invitation']]\n",
    "        decision = decision_note[0]['content']['decision']\n",
    "    else:\n",
    "        decision = ''\n",
    "    # filter reviewer comments\n",
    "    comment_notes = [d for d in item \\\n",
    "                     if 'Official_Review' in d['invitation'] and 'recommendation' in d['content'].keys()]\n",
    "    comment_notes = sorted(comment_notes, key=lambda d: d['number'])[::-1]\n",
    "    ratings = [int(note['content']['recommendation'].split(':')[0]) for note in comment_notes]\n",
    "    confidences = [int(note['content']['confidence'].split(':')[0]) for note in comment_notes]\n",
    "    review_lengths = [sum(len(note['content'][key].split()) for key in review_keys) for note in comment_notes] # review lengths\n",
    "\n",
    "    return {'ratings': ratings, 'confidences': confidences, 'withdraw': withdraw, 'decision': decision, 'review_lengths': review_lengths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e92dd456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1a721092124034b6d2712c00efc61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2628 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter data in a pool of processes\n",
    "with Pool(8) as p:\n",
    "    filtered_notes = list(tqdm(p.imap(filter_data, notes), total=len(notes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0939f79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratings</th>\n",
       "      <th>confidences</th>\n",
       "      <th>withdraw</th>\n",
       "      <th>decision</th>\n",
       "      <th>review_lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[8, 8, 8, 8]</td>\n",
       "      <td>[4, 4, 4, 3]</td>\n",
       "      <td>0</td>\n",
       "      <td>Accept (Spotlight)</td>\n",
       "      <td>[493, 788, 460, 460]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[8, 6, 6, 6]</td>\n",
       "      <td>[3, 3, 2, 3]</td>\n",
       "      <td>0</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[318, 551, 275, 210]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[5, 8, 5, 5]</td>\n",
       "      <td>[4, 5, 4, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[434, 1113, 463, 338]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[6, 6, 6, 6]</td>\n",
       "      <td>[4, 4, 3, 3]</td>\n",
       "      <td>0</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[294, 677, 604, 316]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[6, 6, 6, 6]</td>\n",
       "      <td>[3, 4, 5, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[262, 284, 265, 425]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ratings   confidences  withdraw            decision  \\\n",
       "0  [8, 8, 8, 8]  [4, 4, 4, 3]         0  Accept (Spotlight)   \n",
       "1  [8, 6, 6, 6]  [3, 3, 2, 3]         0     Accept (Poster)   \n",
       "2  [5, 8, 5, 5]  [4, 5, 4, 4]         0     Accept (Poster)   \n",
       "3  [6, 6, 6, 6]  [4, 4, 3, 3]         0     Accept (Poster)   \n",
       "4  [6, 6, 6, 6]  [3, 4, 5, 4]         0     Accept (Poster)   \n",
       "\n",
       "          review_lengths  \n",
       "0   [493, 788, 460, 460]  \n",
       "1   [318, 551, 275, 210]  \n",
       "2  [434, 1113, 463, 338]  \n",
       "3   [294, 677, 604, 316]  \n",
       "4   [262, 284, 265, 425]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "ratings = pd.DataFrame(filtered_notes)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6602e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content.title</th>\n",
       "      <th>content.keywords</th>\n",
       "      <th>ratings</th>\n",
       "      <th>confidences</th>\n",
       "      <th>withdraw</th>\n",
       "      <th>decision</th>\n",
       "      <th>review_lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g1SzIRLQXMM</td>\n",
       "      <td>Wiring Up Vision: Minimizing Supervised Synapt...</td>\n",
       "      <td>[computational neuroscience, primate visual ve...</td>\n",
       "      <td>[8, 8, 8, 8]</td>\n",
       "      <td>[4, 4, 4, 3]</td>\n",
       "      <td>0</td>\n",
       "      <td>Accept (Spotlight)</td>\n",
       "      <td>[493, 788, 460, 460]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HndgQudNb91</td>\n",
       "      <td>Learning to Downsample for Segmentation of Ult...</td>\n",
       "      <td>[ultra-high resolution image segmentation, non...</td>\n",
       "      <td>[8, 6, 6, 6]</td>\n",
       "      <td>[3, 3, 2, 3]</td>\n",
       "      <td>0</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[318, 551, 275, 210]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7fFO4cMBx_9</td>\n",
       "      <td>Variational Neural Cellular Automata</td>\n",
       "      <td>[Neural Cellular Automata, Cellular Automata, ...</td>\n",
       "      <td>[5, 8, 5, 5]</td>\n",
       "      <td>[4, 5, 4, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[434, 1113, 463, 338]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FKp8-pIRo3y</td>\n",
       "      <td>Wish you were here: Hindsight Goal Selection f...</td>\n",
       "      <td>[goal-conditioned reinforcement learning, lear...</td>\n",
       "      <td>[6, 6, 6, 6]</td>\n",
       "      <td>[4, 4, 3, 3]</td>\n",
       "      <td>0</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[294, 677, 604, 316]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KntaNRo6R48</td>\n",
       "      <td>L0-Sparse Canonical Correlation Analysis</td>\n",
       "      <td>[]</td>\n",
       "      <td>[6, 6, 6, 6]</td>\n",
       "      <td>[3, 4, 5, 4]</td>\n",
       "      <td>0</td>\n",
       "      <td>Accept (Poster)</td>\n",
       "      <td>[262, 284, 265, 425]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                      content.title  \\\n",
       "0  g1SzIRLQXMM  Wiring Up Vision: Minimizing Supervised Synapt...   \n",
       "1  HndgQudNb91  Learning to Downsample for Segmentation of Ult...   \n",
       "2  7fFO4cMBx_9               Variational Neural Cellular Automata   \n",
       "3  FKp8-pIRo3y  Wish you were here: Hindsight Goal Selection f...   \n",
       "4  KntaNRo6R48           L0-Sparse Canonical Correlation Analysis   \n",
       "\n",
       "                                    content.keywords       ratings  \\\n",
       "0  [computational neuroscience, primate visual ve...  [8, 8, 8, 8]   \n",
       "1  [ultra-high resolution image segmentation, non...  [8, 6, 6, 6]   \n",
       "2  [Neural Cellular Automata, Cellular Automata, ...  [5, 8, 5, 5]   \n",
       "3  [goal-conditioned reinforcement learning, lear...  [6, 6, 6, 6]   \n",
       "4                                                 []  [6, 6, 6, 6]   \n",
       "\n",
       "    confidences  withdraw            decision         review_lengths  \n",
       "0  [4, 4, 4, 3]         0  Accept (Spotlight)   [493, 788, 460, 460]  \n",
       "1  [3, 3, 2, 3]         0     Accept (Poster)   [318, 551, 275, 210]  \n",
       "2  [4, 5, 4, 4]         0     Accept (Poster)  [434, 1113, 463, 338]  \n",
       "3  [4, 4, 3, 3]         0     Accept (Poster)   [294, 677, 604, 316]  \n",
       "4  [3, 4, 5, 4]         0     Accept (Poster)   [262, 284, 265, 425]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with df_raw_filtered\n",
    "df_final = pd.concat([df_raw_filtered, ratings], axis=1)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d83b433",
   "metadata": {},
   "source": [
    "## Save filtered dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2ab086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe as csv\n",
    "# rename title\n",
    "df_final.rename(columns={'content.title': 'title'}, inplace=True)\n",
    "#rename keywords\n",
    "df_final.rename(columns={'content.keywords': 'keywords'}, inplace=True)\n",
    "df_final.to_csv(f'{DATA_PATH}{venue_short}_{time.strftime(\"%Y%m%d\")}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d32cd65",
   "metadata": {},
   "source": [
    "## Saving full crawled dataset\n",
    "\n",
    "Note that this dataset is raw and contains everyting; so it will be pretty large (>100 MBs)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90c63c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162510/1720629586.py:5: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->axis0] [items->None]\n",
      "\n",
      "  df.to_hdf(f'{DATA_PATH}{venue_short}_data_full_{time.strftime(\"%Y%m%d\")}.h5', key='df', mode='w')\n",
      "/tmp/ipykernel_162510/1720629586.py:5: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index([                            'id',                       'original',\n",
      "                                'mdate',                          'ddate',\n",
      "                               'tddate',                          'forum',\n",
      "                              'replyto',                     'invitation',\n",
      "                           'signatures',                        'readers',\n",
      "                           'nonreaders',                        'writers',\n",
      "                        'content.title',              'content.authorids',\n",
      "                      'content.authors',               'content.keywords',\n",
      "                     'content.abstract',         'content.code_of_ethics',\n",
      "        'content.submission_guidelines',           'content.resubmission',\n",
      "               'content.student_author',      'content.serve_as_reviewer',\n",
      "                    'content.paperhash',                    'content.pdf',\n",
      "         'content.one-sentence_summary',                'content._bibtex',\n",
      "                        'content.venue',                'content.venueid',\n",
      "                         'content.data', 'content.supplementary_material',\n",
      "                         'content.code',                                0,\n",
      "                                      1,                                2,\n",
      "                                      3,                                4,\n",
      "                                      5,                                6,\n",
      "                                      7,                                8,\n",
      "                                      9,                               10,\n",
      "                                     11,                               12,\n",
      "                                     13,                               14,\n",
      "                                     15,                               16,\n",
      "                                     17,                               18,\n",
      "                                     19,                               20,\n",
      "                                     21,                               22,\n",
      "                                     23,                               24,\n",
      "                                     25,                               26,\n",
      "                                     27,                               28,\n",
      "                                     29,                               30,\n",
      "                                     31,                               32,\n",
      "                                     33,                               34,\n",
      "                                     35,                               36,\n",
      "                                     37,                               38,\n",
      "                                     39,                               40,\n",
      "                                     41,                               42,\n",
      "                                     43,                               44,\n",
      "                                     45,                               46,\n",
      "                                     47,                               48,\n",
      "                                     49,                               50,\n",
      "                                     51,                               52,\n",
      "                                     53,                               54,\n",
      "                                     55,                               56,\n",
      "                                     57,                               58,\n",
      "                                     59],\n",
      "      dtype='object')]\n",
      "\n",
      "  df.to_hdf(f'{DATA_PATH}{venue_short}_data_full_{time.strftime(\"%Y%m%d\")}.h5', key='df', mode='w')\n",
      "/tmp/ipykernel_162510/1720629586.py:5: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block1_items] [items->None]\n",
      "\n",
      "  df.to_hdf(f'{DATA_PATH}{venue_short}_data_full_{time.strftime(\"%Y%m%d\")}.h5', key='df', mode='w')\n"
     ]
    }
   ],
   "source": [
    "# Save dataframe as hdf5\n",
    "notes_df = pd.DataFrame([n['notes'] for n in data])\n",
    "count_df = pd.DataFrame({'notes_count': [n['count'] for n in data]})\n",
    "df = pd.concat([df_raw, notes_df, count_df], axis=1)\n",
    "df.to_hdf(f'{DATA_PATH}{venue_short}_data_full_{time.strftime(\"%Y%m%d\")}.h5', key='df', mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
